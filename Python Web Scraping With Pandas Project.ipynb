{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab75f4c7-a228-4a29-b5f3-5ca3fa6f1275",
   "metadata": {},
   "source": [
    "# Python Web Scraping With Pandas Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9872a40-10a7-4b52-a6aa-1d5666674ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc72a88a-ab66-42e0-8d94-03a577b19c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 done\n",
      "Page 2 done\n",
      "Page 3 done\n",
      "Page 4 done\n",
      "Page 5 done\n",
      "Page 6 done\n",
      "Page 7 done\n",
      "Page 8 done\n",
      "Page 9 done\n",
      "Page 10 done\n",
      "Page 11 done\n",
      "Page 12 done\n",
      "Page 13 done\n",
      "Page 14 done\n",
      "Page 15 done\n",
      "Page 16 done\n",
      "Page 17 done\n",
      "Page 18 done\n",
      "Page 19 done\n",
      "Page 20 done\n",
      "Page 21 done\n",
      "Page 22 done\n",
      "Page 23 done\n",
      "Page 24 done\n",
      "Page 25 done\n",
      "Page 26 done\n",
      "Page 27 done\n",
      "Page 28 done\n",
      "Page 29 done\n",
      "Page 30 done\n",
      "Page 31 done\n",
      "Page 32 done\n",
      "Page 33 done\n",
      "Page 34 done\n",
      "Page 35 done\n",
      "Page 36 done\n",
      "Page 37 done\n",
      "Page 38 done\n",
      "Page 39 done\n",
      "Page 40 done\n",
      "Page 41 done\n",
      "Page 42 done\n",
      "Page 43 done\n",
      "Page 44 done\n",
      "Page 45 done\n",
      "Page 46 done\n",
      "Page 47 done\n",
      "Page 48 done\n",
      "Page 49 done\n",
      "Page 50 done\n",
      "CSV saved to D:\\All\\Needing Data\\books_to_scrape_1000.csv\n",
      "                                   Title  Price Availability Rating\n",
      "0                   A Light in the Attic  51.77     In stock  Three\n",
      "1                     Tipping the Velvet  53.74     In stock    One\n",
      "2                             Soumission  50.10     In stock    One\n",
      "3                          Sharp Objects  47.82     In stock   Four\n",
      "4  Sapiens: A Brief History of Humankind  54.23     In stock   Five\n",
      "Total books scraped: 1000\n"
     ]
    }
   ],
   "source": [
    "book_list = []\n",
    "\n",
    "book_count = 0\n",
    "\n",
    "for page in range(1, 51):  # 50 pages × 20 books = 1000 books\n",
    "    url = f\"http://books.toscrape.com/catalogue/page-{page}.html\"\n",
    "    soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "    \n",
    "    for book in soup.find_all(\"article\", class_=\"product_pod\"):\n",
    "        title = book.h3.a['title']\n",
    "        price = float(book.find(\"p\", class_=\"price_color\").text.replace(\"£\", \"\").replace(\"Â\", \"\").strip())\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").text.strip().replace(\"\\n\", \"\")\n",
    "        rating = book.p['class'][1]\n",
    "        \n",
    "        book_list.append([title, price, availability, rating])\n",
    "        book_count += 1\n",
    "        \n",
    "        if book_count >= 1000:  # stop after 1000 books\n",
    "            break\n",
    "    \n",
    "    print(f\"Page {page} done\")\n",
    "    \n",
    "    if book_count >= 1000:\n",
    "        break\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(book_list, columns=[\"Title\", \"Price\", \"Availability\", \"Rating\"])\n",
    "\n",
    "# Save CSV in current folder\n",
    "csv_path = r\"D:\\All\\Needing Data\\books_to_scrape_1000.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"CSV saved to {csv_path}\")\n",
    "\n",
    "# Load CSV to check\n",
    "df_loaded = pd.read_csv(csv_path)\n",
    "print(df_loaded.head())\n",
    "print(\"Total books scraped:\", len(df_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584835e-d4ca-45a4-91de-eb9b85a13bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af2174-4847-438c-a6e5-274a9756c308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
